# LLMs-based Low-level Vision Methods

## LMMs-based-image-restoration-and-enhancement

\- **[ECCV 2024]** [Autodir: Automatic all-in-one image restoration with latent diffusion](https://arxiv.org/abs/2310.10123), Jiang et al. [Github](https://github.com/jiangyitong/AutoDIR) | [Bibtex](https://scholar.googleusercontent.com/scholar.bib?q=info:6sXjvxd4pcQJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KCkb7I:AFWwaeYAAAAAZxeid7KbRXKSv7Dn_TjmRpgI7N8&scisig=AFWwaeYAAAAAZxeid5eOjx0wTGSBmN-Z9yvCiyI&scisf=4&ct=citation&cd=-1&hl=zh-CN) | [Project Page](https://jiangyitong.github.io/AutoDIR_webpage/)

\- **[arXiv 2024]** [Low-light image enhancement via clip-fourier guided wavelet diffusion](https://arxiv.org/abs/2401.03788), Xue et al. [Github](https://github.com/hejh8/CFWD) | [Bibtex](https://scholar.googleusercontent.com/scholar.bib?q=info:VAq5NzyNbNUJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KCl7rg:AFWwaeYAAAAAZxej9rg_zyTnX5Ey8YMA1pRdaL4&scisig=AFWwaeYAAAAAZxej9qONoGjH4gmCXF9CAKHEyjQ&scisf=4&ct=citation&cd=-1&hl=zh-CN) 

\- **[CVPR 2024]** [Coser: Bridging image and language for cognitive super-resolution](https://openaccess.thecvf.com/content/CVPR2024/papers/Sun_CoSeR_Bridging_Image_and_Language_for_Cognitive_Super-Resolution_CVPR_2024_paper.pdf), Sun et al. [Github](https://github.com/VINHYU/CoSeR) | [Bibtex](https://scholar.googleusercontent.com/scholar.bib?q=info:7jW1-6qKZdcJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KCjePI:AFWwaeYAAAAAZxelYPJhs9_iOb89mTQG7tZvhmQ&scisig=AFWwaeYAAAAAZxelYLYLZ_zDGw_93tOoqeNkRKQ&scisf=4&ct=citation&cd=-1&hl=zh-CN) | [Project Page](https://coser-main.github.io/)

\- **[arXiv 2023]** [Diffbir: Towards blind image restoration with generative diffusion prior](https://arxiv.org/abs/2308.15070), Lin et al. [Github](https://github.com/XPixelGroup/DiffBIR) | [Bibtex](https://scholar.googleusercontent.com/scholar.bib?q=info:Z9Dr2UUhFNQJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KCjlSQ:AFWwaeYAAAAAZxeljSQxgaPG5JwtpqV9UNeWcAA&scisig=AFWwaeYAAAAAZxeljU83oda023AQgKnWJpr5ILQ&scisf=4&ct=citation&cd=-1&hl=zh-CN) | [Project Page](https://0x3f3f3f3fun.github.io/projects/diffbir/)

\- **[arXiv 2023]** [Pixel-aware stable diffusion for realistic image super-resolution and personalized stylization](https://arxiv.org/abs/2308.14469), Yang et al. [Github](https://github.com/yangxy/PASD/) | [Bibtex](https://scholar.googleusercontent.com/scholar.bib?q=info:4XOa6dxjwFgJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KCv2Ig:AFWwaeYAAAAAZxepwIivvmkw8YrkpEau3ItHTnk&scisig=AFWwaeYAAAAAZxepwCA_kbClU0MbzTok-q1OW3I&scisf=4&ct=citation&cd=-1&hl=zh-CN)

\- **[CVPR 2024]** [Scaling up to excellence: Practicing model scaling for photo-realistic image restoration in the wild](https://openaccess.thecvf.com/content/CVPR2024/papers/Yu_Scaling_Up_to_Excellence_Practicing_Model_Scaling_for_Photo-Realistic_Image_CVPR_2024_paper.pdf), Yu et al. [Github](https://github.com/Fanghua-Yu/SUPIR) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:jD51y2ylzdEJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KCt854:AFWwaeYAAAAAZxer655JY-HHbt26fi-b9qVFMsY&scisig=AFWwaeYAAAAAZxer69Tqc127xXFMC2FikZF6IWA&scisf=4&ct=citation&cd=-1&hl=zh-CN) | [Project Page](https://supir.xpixel.group/)

\- **[ICLR 2024]** [Controlling Vision-Language Models for Multi-Task Image Restoration](https://openreview.net/pdf?id=t3vnnLeajU), Luo et al. [Github](https://github.com/Algolzw/daclip-uir) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:FCGDFRR7sMAJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KCqNII:AFWwaeYAAAAAZxesLIIKoJBpt9CW_4NK-oYbXLI&scisig=AFWwaeYAAAAAZxesLLHnZTkfp6lVaqSeIgEQpHI&scisf=4&ct=citation&cd=-1&hl=zh-CN) | [Project Page](https://algolzw.github.io/daclip-uir)

\- **[ICCV 2023]** [Multiscale structure guided diffusion for image deblurring](https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Multiscale_Structure_Guided_Diffusion_for_Image_Deblurring_ICCV_2023_paper.pdf), Ren et al.  [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:Lnr_iE0hujMJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KCoGwM:AFWwaeYAAAAAZxeuAwOciKJh8vec22a4j4TgW_4&scisig=AFWwaeYAAAAAZxeuA95LFwsbIE8cQKqAZqwE-yE&scisf=4&ct=citation&cd=-1&hl=zh-CN) 

\- **[CVPR 2023]** [Generative diffusion prior for unified image restoration and enhancement](https://openaccess.thecvf.com/content/CVPR2023/papers/Fei_Generative_Diffusion_Prior_for_Unified_Image_Restoration_and_Enhancement_CVPR_2023_paper.pdf), Fei et al.  [Github](https://github.com/Fayeben/GenerativeDiffusionPrior) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:U0dGUi_bDfIJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KCoIjs:AFWwaeYAAAAAZxeuOjsc9Kx7TCdQ9FEblvwCvHo&scisig=AFWwaeYAAAAAZxeuOmnDoicktLHbRroGQ4v-C6s&scisf=4&ct=citation&cd=-1&hl=zh-CN) | [Project Page](https://generativediffusionprior.github.io/)

\- **[IJCV 2024]** [Exploiting diffusion prior for real-world image super-resolution](https://arxiv.org/pdf/2305.07015), Wang et al. [Github](https://github.com/IceClear/StableSR) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:Uq3Tsz1HxqAJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KCo9n0:AFWwaeYAAAAAZxeu7n3vBkwjfi2s7tHFIxgDwpQ&scisig=AFWwaeYAAAAAZxeu7u0L_T19RNdop7R7zWEVgDk&scisf=4&ct=citation&cd=-1&hl=zh-CN) | [Project Page](https://iceclear.github.io/projects/stablesr/)

\- **[ICCV 2023]** [Iterative prompt learning for unsupervised backlit image enhancement](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Iterative_Prompt_Learning_for_Unsupervised_Backlit_Image_Enhancement_ICCV_2023_paper.pdf), Liang et al. [Github](https://github.com/ZhexinLiang/CLIP-LIT) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:f00V76nfpk8J:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KCplGA:AFWwaeYAAAAAZxevjGCqVoHj9DqEx1UODMlYpNE&scisig=AFWwaeYAAAAAZxevjMknalevMln4QuWxHAxDM4k&scisf=4&ct=citation&cd=-1&hl=zh-CN) | [Project Page](https://zhexinliang.github.io/CLIP_LIT_page/)

\- **[TOG 2023]** [Low-light image enhancement with wavelet-based diffusion models](https://arxiv.org/pdf/2306.00306.pdf), Jiang et al. [Github](https://github.com/JianghaiSCU/Diffusion-Low-Light) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:KjhNUcjPD8UJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KC2hAI:AFWwaeYAAAAAZxewnALbRSFZ9WoUQRROb3BJAPk&scisig=AFWwaeYAAAAAZxewnCfyAs8Gp13bbtfgadluAdY&scisf=4&ct=citation&cd=-1&hl=zh-CN) 

\- **[arXiv 2023]** [A dive into sam prior in image restoration](https://arxiv.org/pdf/2305.13620), Xiao et al. [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:j_8NvA7wIkkJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KC3d64:AFWwaeYAAAAAZxexb65Q3Xd6HPVeGm9SvR5og_s&scisig=AFWwaeYAAAAAZxexbzvCxyuh8Uj_Lnc0NpeDE_4&scisf=4&ct=citation&cd=-1&hl=zh-CN)

\- **[CVPR 2024]** [Distilling Semantic Priors from SAM to Efficient Image Restoration Models](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Distilling_Semantic_Priors_from_SAM_to_Efficient_Image_Restoration_Models_CVPR_2024_paper.pdf), Zhang et al.[Github](https://github.com/DrizzleSail/SAM4IR) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:WKOVVIIHNXAJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KC3yM0:AFWwaeYAAAAAZxex0M11RhMP3C4urV9iuJrhj-4&scisig=AFWwaeYAAAAAZxex0Ldn78il8KKYj7pWX1f4TU4&scisf=4&ct=citation&cd=-1&hl=zh-CN)

\- **[IEEE TMM 2024]** [Low-light Image Enhancement with SAM-based Structure Priors and Guidance](https://ieeexplore.ieee.org/abstract/document/10557144/), Li et al. [Github]() | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:Nbno0UzUlEwJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KC0j94:AFWwaeYAAAAAZxeyl97w_CAunffeIKwkepguphI&scisig=AFWwaeYAAAAAZxeyl_6UEYrYO0gOGWtpmFm5Tzw&scisf=4&ct=citation&cd=-1&hl=zh-CN)

\- **[arXiv 2024]** [LM4LV: A Frozen Large Language Model for Low-level Vision Tasks](https://arxiv.org/pdf/2405.15734), Zheng et al. [Github](https://github.com/bytetriper/LM4LV) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:Jq8zYzzp1KwJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KC1bO0:AFWwaeYAAAAAZxezdO31yjgQp91Msxwy5INsiKU&scisig=AFWwaeYAAAAAZxezdH2RVDjSpHyWQ_K-XteO0Hc&scisf=4&ct=citation&cd=-1&hl=zh-CN) 

\- **[arXiv 2024]** [LLMRA: Multi-modal Large Language Model based Restoration Assistant](https://arxiv.org/pdf/2401.11401), Jin et al. [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:2JHom-jMoY8J:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KC1wn8:AFWwaeYAAAAAZxez2n9tH2iEJfeH6_5y7GND0-E&scisig=AFWwaeYAAAAAZxez2r2qdwFn1xGXoyZGKu1G1RM&scisf=4&ct=citation&cd=-1&hl=zh-CN) 

\- **[arXiv 2024]** [RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models](https://arxiv.org/abs/2407.18035), Chen et al. [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:k-v0THlvJpwJ:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KCyRbs:AFWwaeYAAAAAZxe0Xbtyc1AALG7G2R7f0yyLuTY&scisig=AFWwaeYAAAAAZxe0XTG5CmTpPbZYi1eIRitAdGE&scisf=4&ct=citation&cd=-1&hl=zh-CN) | [Project Page](https://haoyuchen.com/RestoreAgent)

\- **[arXiv 2023]** [Clarity ChatGPT: An Interactive and Adaptive Processing System for Image Restoration and Enhancement](https://arxiv.org/pdf/2311.11695), Wei et al. [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:_KIZtlkHPg0J:scholar.google.com/&output=citation&scisdr=ClHXZ7pUEMTX-KCy5nY:AFWwaeYAAAAAZxe0_nZO0H4rPWDUQgycNRtxNww&scisig=AFWwaeYAAAAAZxe0_oTfrjidJRM10VGRPL_nhr4&scisf=4&ct=citation&cd=-1&hl=zh-CN)

## LMMs-based-IQA

- **[ICLR 2024]** [Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision](https://arxiv.org/abs/2309.14181), Wu et al. [Github](https://github.com/Q-Future/Q-Bench) | [Bibtex](https://arxiv.org/bibtex/2309.14181) | [Dataset](https://github.com/Q-Future/Q-Bench/releases/tag/v1.0.1.1014datarelease)

- **[AAAI 2023]** [Exploring CLIP for Assessing the Look and Feel of Images](https://arxiv.org/abs/2207.12396), Wang et al. [Github](https://github.com/IceClear/CLIP-IQA) | [Bibtex](https://arxiv.org/bibtex/2207.12396)

- **[arXiv 2023]** [Q-Boost: On Visual Quality Assessment Ability of Low-level Multi-Modality Foundation Models](https://arxiv.org/abs/2312.15300), Zhang et al. [Bibtex](https://arxiv.org/bibtex/2312.15300)

- **[arXiv 2023]** [Q-Align: Teaching LMMs for Visual Scoring via Discrete Text-defined Levels](https://arxiv.org/abs/2312.17090), Wu et al. [Project](https://q-align.github.io/) | [Github](https://github.com/Q-Future/Q-Align) | [Bibtex](https://arxiv.org/bibtex/2312.17090)

- **[CVPR 2023]** [Blind Image Quality Assessment via Vision-Language Correspondence: A Multitask Learning Perspective](https://arxiv.org/abs/2303.14968), Zhang et al. [Github](https://github.com/zwx8981/LIQE) | [Bibtex](https://arxiv.org/bibtex/2303.14968)

- **[arXiv 2024]** [CLIP-Guided Attribute Aware Pretraining for Generalizable Image Quality Assessment](https://arxiv.org/abs/2406.01020), Kwon et al. [Bibtex](https://arxiv.org/bibtex/2406.01020)

- **[arXiv 2024]** [Q-Ground: Image Quality Grounding with Large Multi-modality Models](https://arxiv.org/abs/2407.17035), Chen et al. [Github](https://github.com/Q-Future/Q-Ground) | [Bibtex](https://arxiv.org/bibtex/2407.17035)

- **[arXiv 2023]** [Depicting Beyond Scores: Advancing Image Quality Assessment through Multi-Modal Language Models](https://arxiv.org/abs/2312.08962), You et al. [Project](https://depictqa.github.io/) | [Bibtex](https://arxiv.org/bibtex/2312.08962)

- **[arXiv 2023]** [Q-Instruct: Improving Low-level Visual Abilities for Multi-modality Foundation Models](https://arxiv.org/abs/2311.06783), Wu et al. [Project](https://q-future.github.io/Q-Instruct/) | [Bibtex](https://arxiv.org/bibtex/2311.06783)

- **[arXiv 2024]** [Descriptive Image Quality Assessment in the Wild](https://arxiv.org/abs/2405.18842), You et al. [Project](https://depictqa.github.io/depictqa-wild/) | [Github](https://github.com/XPixelGroup/DepictQA) | [Bibtex](https://arxiv.org/bibtex/2405.18842)

- **[arXiv 2024]** [Towards Open-ended Visual Quality Comparison](https://arxiv.org/abs/2402.16641), Wu et al. [Project](https://huggingface.co/q-future/co-instruct) | [Bibtex](https://arxiv.org/bibtex/2402.16641)

- **[arXiv 2024]** [Adaptive Image Quality Assessment via Teaching Large Multimodal Model to Compare](https://arxiv.org/abs/2405.19298), Zhu et al. [Project](https://compare2score.github.io/) | [Github](https://github.com/Q-Future/Compare2Score) | [Bibtex](https://arxiv.org/bibtex/2405.19298)
